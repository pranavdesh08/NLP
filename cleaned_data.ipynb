{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we clean the data and store in a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re # regex lib for cleaning\n",
    "from nltk.corpus import stopwords # list of stopwords\n",
    "from nltk.stem import WordNetLemmatizer # for lemmatizing (years to year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>url_website</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_website</th>\n",
       "      <th>company_logo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excellent ...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.trustpilot.com/review/rentokil.com</td>\n",
       "      <td>Rentokil</td>\n",
       "      <td>http://rentokil.com?utm_medium=company_profile...</td>\n",
       "      <td>//s3-eu-west-1.amazonaws.com/tpd/screenshots/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dog become healthy. Thank you.</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.trustpilot.com/review/www.topdogra...</td>\n",
       "      <td>Topdograwfoods</td>\n",
       "      <td>http://www.topdograwfoods.com?utm_medium=compa...</td>\n",
       "      <td>//s3-eu-west-1.amazonaws.com/tpd/screenshots/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quality service, everyone is happy.</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.trustpilot.com/review/www.topdogra...</td>\n",
       "      <td>Topdograwfoods</td>\n",
       "      <td>http://www.topdograwfoods.com?utm_medium=compa...</td>\n",
       "      <td>//s3-eu-west-1.amazonaws.com/tpd/screenshots/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Went to Top Dog raw food this morning for the ...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.trustpilot.com/review/www.topdogra...</td>\n",
       "      <td>Topdograwfoods</td>\n",
       "      <td>http://www.topdograwfoods.com?utm_medium=compa...</td>\n",
       "      <td>//s3-eu-west-1.amazonaws.com/tpd/screenshots/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very stylish site, has enough information to m...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.trustpilot.com/review/www.topdogra...</td>\n",
       "      <td>Topdograwfoods</td>\n",
       "      <td>http://www.topdograwfoods.com?utm_medium=compa...</td>\n",
       "      <td>//s3-eu-west-1.amazonaws.com/tpd/screenshots/5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  rating  \\\n",
       "0                                      Excellent ...       5   \n",
       "1                 The dog become healthy. Thank you.       5   \n",
       "2                Quality service, everyone is happy.       5   \n",
       "3  Went to Top Dog raw food this morning for the ...       5   \n",
       "4  Very stylish site, has enough information to m...       5   \n",
       "\n",
       "                                         url_website    company_name  \\\n",
       "0     https://www.trustpilot.com/review/rentokil.com        Rentokil   \n",
       "1  https://www.trustpilot.com/review/www.topdogra...  Topdograwfoods   \n",
       "2  https://www.trustpilot.com/review/www.topdogra...  Topdograwfoods   \n",
       "3  https://www.trustpilot.com/review/www.topdogra...  Topdograwfoods   \n",
       "4  https://www.trustpilot.com/review/www.topdogra...  Topdograwfoods   \n",
       "\n",
       "                                     company_website  \\\n",
       "0  http://rentokil.com?utm_medium=company_profile...   \n",
       "1  http://www.topdograwfoods.com?utm_medium=compa...   \n",
       "2  http://www.topdograwfoods.com?utm_medium=compa...   \n",
       "3  http://www.topdograwfoods.com?utm_medium=compa...   \n",
       "4  http://www.topdograwfoods.com?utm_medium=compa...   \n",
       "\n",
       "                                        company_logo  \n",
       "0  //s3-eu-west-1.amazonaws.com/tpd/screenshots/5...  \n",
       "1  //s3-eu-west-1.amazonaws.com/tpd/screenshots/5...  \n",
       "2  //s3-eu-west-1.amazonaws.com/tpd/screenshots/5...  \n",
       "3  //s3-eu-west-1.amazonaws.com/tpd/screenshots/5...  \n",
       "4  //s3-eu-west-1.amazonaws.com/tpd/screenshots/5...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_csv('comments_trustpilot_en.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The above DataFrame contains extra information which is not needed to train/test the model. For the purpose of training/testing we will be using 1st, & 2nd columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excellent ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dog become healthy. Thank you.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quality service, everyone is happy.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Went to Top Dog raw food this morning for the ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very stylish site, has enough information to m...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  rating\n",
       "0                                      Excellent ...       5\n",
       "1                 The dog become healthy. Thank you.       5\n",
       "2                Quality service, everyone is happy.       5\n",
       "3  Went to Top Dog raw food this morning for the ...       5\n",
       "4  Very stylish site, has enough information to m...       5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:,:2]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1194983, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment    0\n",
       "rating     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st review: Excellent ...\n",
      "2nd review: The dog become healthy. Thank you.\n",
      "3nd review: As good as always. The Lobophyllia coral was placed in tank on Thursday and  has had two feeds so far and has puffed up nice. Lovely coral. Thanks again for top corals and service. Colin Forsdick.\n"
     ]
    }
   ],
   "source": [
    "print('1st review:',df.iloc[0,0])\n",
    "print('2nd review:',df.iloc[1,0])\n",
    "print('3nd review:',df.iloc[43,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To remove the stopwords such as 'is, the, to' stop_words is a set containing all the stopwords in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {'a','about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\",\n",
    "             'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn',\n",
    "             \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during',\n",
    "             'each', 'few', 'for', 'from', 'further', 'go', 'g', 'goes', 'get', 'got', 'gave', 'getting', 'gets','gives', 'given', \n",
    "              'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have','haven',\"haven't\",'having','he','her','here','hers','herself',\n",
    "              'him','himself','his', 'hmm', 'how','i','if','in','into','is','isn',\"isn't\",'it',\"it's\",'its','itself','just','ll','m','ma',\n",
    "              'me','mightn',\"mightn't\",'more','most','mustn',\"mustn't\",'my','myself','needn',\"needn't\",'now','o','of','off','on',\n",
    "              'once','only','or','other','our','ours','ourselves','out','over','own','re','s','same','shan',\"shan't\",'she',\"she's\",\n",
    "              'should',\"should've\",'shouldn',\"shouldn't\",'so','some','such','t','than','that',\"that'll\",'the','their','theirs',\n",
    "              'them','themselves','then','there','these','they','this','those','through','to','too','under','until','up','umm', 've',\n",
    "              'was','wasn',\"wasn't\",'we','were','weren',\"weren't\",'what','when','where','which','while','who','whom','why','will',\n",
    "              'with','won',\"won't\",'wouldn',\"wouldn't\",'y','you',\"you'd\",\"you'll\",\"you're\",\"you've\",'your','yours','yourself',\n",
    "              'yourselves'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The words like ' aren't, isn't ' are converted to 'are not, is not' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the data cleaning part.\n",
    "### step1 lower the entire sentence, so that 'he' and 'HE' is not treated as a different words.\n",
    "### step2 contraction_mapping replace words 'aren't to are not' etc.\n",
    "### step3 remove special characters such as ' * ( ] \" ' and keep characters a-z in the reviews.\n",
    "### step4 LEMMATIZATION convert the words to it's root form. (historical --> history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "def clean_review(review):\n",
    "    \n",
    "    review = review.lower()\n",
    "    review = ' '.join([contraction_mapping[w] if w in contraction_mapping else w for w in review.split(\" \")])\n",
    "    review = re.sub(r'\\([^)]*\\)', '', review)\n",
    "    review = re.sub('\"','', review)\n",
    "    review = re.sub(r\"'s\\b\",\"\",review)\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
    "    review = re.sub('[m]{2,}', 'mm', review)\n",
    "    review = ' '.join([lemma.lemmatize(stop) for stop in review.split(' ') if stop not in stop_words and len(stop)>1])\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = []\n",
    "for i in df.iloc[:,0]:\n",
    "    cleaned_reviews.append(clean_review(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excellent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog become healthy thank</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quality service everyone happy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>went top dog raw food morning first time amazi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>very stylish site enough information make choi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     cleaned_reviews  rating\n",
       "0                                          excellent       5\n",
       "1                           dog become healthy thank       5\n",
       "2                     quality service everyone happy       5\n",
       "3  went top dog raw food morning first time amazi...       5\n",
       "4  very stylish site enough information make choi...       5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_reviews'] = cleaned_reviews\n",
    "df = df[['cleaned_reviews','rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved the cleaned data in a new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = []\n",
    "for ind, i in enumerate(cleaned_reviews):\n",
    "    if len(cleaned_reviews[ind].split())==0:\n",
    "        empty.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1194697, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df.index[empty], inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_reviews.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
